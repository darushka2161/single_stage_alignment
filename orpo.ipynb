{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers trl datasets llm_blender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоги эксперементов\n",
    "## Метод обучения - win rate  \n",
    "ORPO из коробки - 0.08  \n",
    "ORPO c PRL - 0.04  \n",
    "SFT + ORPO - 0.07  \n",
    "SFT + OR - 0.11\n",
    "\n",
    "Использование PRL ухудшает результаты (win rate падает до 4%). Это может говорить о том, что PRL слишком сильно ограничивает обновления параметров модели, снижая её способность к адаптации. Возможно, модель становится слишком консервативной и просто не делает изменений, которые могли бы привести к победе над эталоном.  \n",
    "\n",
    "FT + OR (11%) — лучший результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T21:57:08.736732Z",
     "iopub.status.busy": "2025-03-04T21:57:08.736446Z",
     "iopub.status.idle": "2025-03-04T21:57:08.742300Z",
     "shell.execute_reply": "2025-03-04T21:57:08.741221Z",
     "shell.execute_reply.started": "2025-03-04T21:57:08.736708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import ORPOTrainer, ORPOConfig, SFTTrainer, SFTConfig\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import llm_blender\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import TrainingArguments\n",
    "from datasets import Dataset\n",
    "import gc\n",
    "import subprocess\n",
    "from typing import Union, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T21:57:08.744674Z",
     "iopub.status.busy": "2025-03-04T21:57:08.744384Z",
     "iopub.status.idle": "2025-03-04T21:57:09.532319Z",
     "shell.execute_reply": "2025-03-04T21:57:09.531469Z",
     "shell.execute_reply.started": "2025-03-04T21:57:08.744649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Загрузка модели и токенизатора\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T21:57:09.533535Z",
     "iopub.status.busy": "2025-03-04T21:57:09.533275Z",
     "iopub.status.idle": "2025-03-04T21:57:09.537520Z",
     "shell.execute_reply": "2025-03-04T21:57:09.536579Z",
     "shell.execute_reply.started": "2025-03-04T21:57:09.533514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer.chat_template = \"{% for message in messages %}{{message['content'] + '\\n'}}{% endfor %}{% if add_generation_prompt %}{% endif %}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T21:57:09.538822Z",
     "iopub.status.busy": "2025-03-04T21:57:09.538425Z",
     "iopub.status.idle": "2025-03-04T21:57:30.204578Z",
     "shell.execute_reply": "2025-03-04T21:57:30.203512Z",
     "shell.execute_reply.started": "2025-03-04T21:57:09.538790Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42919d88f9943c1958e7aebc2e9b6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/6.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa137b600724307878b87b4867f0b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_prefs-00000-of-00001.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8b6a89403d463da02afea79412113f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_prefs-00000-of-00001.parquet:   0%|          | 0.00/7.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561e311478b541ef8bc4da0fa4fae375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_sft-00000-of-00001.parquet:   0%|          | 0.00/3.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d639c8905a42aa9ee1b02d01c62292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_gen-00000-of-00001.parquet:   0%|          | 0.00/184M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bc388a9e094dc6abe3972a3392b70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_gen-00000-of-00001.parquet:   0%|          | 0.00/3.02M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5fe3f46a704f768fc2204b2745c413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_prefs split:   0%|          | 0/61135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa34ada755b449da595910444955a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_sft split:   0%|          | 0/61135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7868ead04048b2858c61fd7c46e12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_prefs split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edaa2ce3c684582b6f78de0fa0bd2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_sft split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b821bd736248d2878d3fdf0862e073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_gen split:   0%|          | 0/61135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72639e9d45041a5af6b620be7674714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_gen split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9816dc7af93943cc94eb64a2c528af16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3faf89a5572d44a88dc61078eae025ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def load_and_preprocess_dataset():\n",
    "    dataset = load_dataset(\"HuggingFaceH4/ultrafeedback_binarized\")\n",
    "    \n",
    "    def preprocess(example):\n",
    "        return {\n",
    "            \"prompt\": example[\"prompt\"],\n",
    "            \"chosen\": example[\"chosen\"],\n",
    "            \"rejected\": example[\"rejected\"]\n",
    "        }\n",
    "    \n",
    "    # Предобработка тренировочного набора данных\n",
    "    train_dataset = dataset[\"train_prefs\"].map(preprocess, remove_columns=[\"messages\"])\n",
    "    test_dataset = dataset[\"test_prefs\"].map(preprocess, remove_columns=[\"messages\"])\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "train_dataset, test_dataset = load_and_preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T21:57:30.208972Z",
     "iopub.status.busy": "2025-03-04T21:57:30.208694Z",
     "iopub.status.idle": "2025-03-04T21:57:30.218835Z",
     "shell.execute_reply": "2025-03-04T21:57:30.217919Z",
     "shell.execute_reply.started": "2025-03-04T21:57:30.208949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select(range(6000)) \n",
    "test_dataset = test_dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORPO из коробки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T21:57:30.220081Z",
     "iopub.status.busy": "2025-03-04T21:57:30.219831Z",
     "iopub.status.idle": "2025-03-04T21:57:31.460380Z",
     "shell.execute_reply": "2025-03-04T21:57:31.459685Z",
     "shell.execute_reply.started": "2025-03-04T21:57:30.220044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = ORPOConfig(output_dir=\"./orpo\",\n",
    "                           learning_rate = 8e-6,\n",
    "                           lr_scheduler_type=\"linear\",\n",
    "                           beta=0.1,\n",
    "                           per_device_train_batch_size=1,\n",
    "                           gradient_accumulation_steps=16,\n",
    "                           num_train_epochs=2,\n",
    "                           logging_steps=10,\n",
    "                           warmup_steps=10,\n",
    "                           report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T21:57:31.461445Z",
     "iopub.status.busy": "2025-03-04T21:57:31.461200Z",
     "iopub.status.idle": "2025-03-04T23:16:53.938256Z",
     "shell.execute_reply": "2025-03-04T23:16:53.937385Z",
     "shell.execute_reply.started": "2025-03-04T21:57:31.461416Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/orpo_trainer.py:275: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2122436a40348a0a76383fd20839627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05c48f024da46a9b189b0162f0bd599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f4faa4819c485c963ac20b905e7342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='374' max='374' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [374/374 1:18:31, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.179200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.096800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.109300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.061800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.051200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.940500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.939500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.959600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.953900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.958300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.981100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.968500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.061000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.029100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.982700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.992100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.959800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.988700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.928600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.966800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.035900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=374, training_loss=2.0208335152284347, metrics={'train_runtime': 4726.024, 'train_samples_per_second': 2.539, 'train_steps_per_second': 0.079, 'total_flos': 0.0, 'train_loss': 2.0208335152284347, 'epoch': 1.992})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ORPOTrainer(model=model,\n",
    "                      args=training_args,\n",
    "                      processing_class=tokenizer,\n",
    "                      train_dataset=train_dataset)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T23:16:53.939420Z",
     "iopub.status.busy": "2025-03-04T23:16:53.939138Z",
     "iopub.status.idle": "2025-03-04T23:16:54.796961Z",
     "shell.execute_reply": "2025-03-04T23:16:54.796118Z",
     "shell.execute_reply.started": "2025-03-04T23:16:53.939399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T23:16:54.798073Z",
     "iopub.status.busy": "2025-03-04T23:16:54.797777Z",
     "iopub.status.idle": "2025-03-04T23:16:54.808499Z",
     "shell.execute_reply": "2025-03-04T23:16:54.807397Z",
     "shell.execute_reply.started": "2025-03-04T23:16:54.798044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "strt_texts = []\n",
    "for dialog in test_dataset[\"chosen\"]:\n",
    "    strt_texts.append(tokenizer.apply_chat_template(dialog, tokenize=False))\n",
    "\n",
    "prompts = test_dataset[\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T23:16:54.809765Z",
     "iopub.status.busy": "2025-03-04T23:16:54.809442Z",
     "iopub.status.idle": "2025-03-04T23:17:22.419802Z",
     "shell.execute_reply": "2025-03-04T23:17:22.418889Z",
     "shell.execute_reply.started": "2025-03-04T23:16:54.809719Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757e921b6bb44801abed0254c7cac5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc24dbb791c43b8b2780e5157a6706e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/13.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7808772472664367bd2e581108205025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1517aa642c4701a579fbec53dd9355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa621847a4047e08e1035e18b417345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ranker_config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fd312b4f804162b4f82a0d7228b209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97afc336cb8b41829c3d4e2821433d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/130 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6140b951ceac49f1bdf934e95bc0a7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500854b2e51542138564aedda122c115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad81494d6b71493695f02398cd0413a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a19c26bc334ea1803c5f0d74b0dfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d838c751c4c64a20b78ce773e2f116f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/dataclasses_json/core.py:201: RuntimeWarning: 'NoneType' object value of non-optional type load_checkpoint detected when decoding RankerConfig.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/dataclasses_json/core.py:201: RuntimeWarning: 'NoneType' object value of non-optional type device detected when decoding RankerConfig.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46676d17cb3a4a52b33b0384d87c631a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664b2273cc774d799a6572459c082533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a639c5d790420c8782f795596fd077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da01db5ba35416986a0f0f61bfdda83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ranker from  /root/.cache/huggingface/hub/llm-blender/PairRM\n"
     ]
    }
   ],
   "source": [
    "blender = llm_blender.Blender()\n",
    "blender.loadranker(\"llm-blender/PairRM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T23:17:22.424065Z",
     "iopub.status.busy": "2025-03-04T23:17:22.423831Z",
     "iopub.status.idle": "2025-03-04T23:17:22.429760Z",
     "shell.execute_reply": "2025-03-04T23:17:22.428670Z",
     "shell.execute_reply.started": "2025-03-04T23:17:22.424044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_win_rate(model, tokenizer, test_dataset, blender, device='cuda'):\n",
    "    win_count = 0\n",
    "    inputs = tokenizer(test_dataset[\"prompt\"], return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    model_responses = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    candidates = list(zip(model_responses, strt_texts))\n",
    "    scores = blender.rank(inputs=test_dataset[\"prompt\"], candidates=candidates, return_scores=False, batch_size=1)\n",
    "    # print(scores)\n",
    "    win_count = sum([np.argmax(rank) == 1 for rank in scores])\n",
    "    win_rate = win_count / len(test_dataset)\n",
    "    print(f\"Win rate: {win_rate * 100:.2f}%\")\n",
    "    return win_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T23:17:22.431220Z",
     "iopub.status.busy": "2025-03-04T23:17:22.431003Z",
     "iopub.status.idle": "2025-03-04T23:18:26.816869Z",
     "shell.execute_reply": "2025-03-04T23:18:26.816105Z",
     "shell.execute_reply.started": "2025-03-04T23:17:22.431200Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Ranking candidates: 100%|██████████| 100/100 [00:41<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate: 8.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_win_rate(trainer.model, tokenizer, test_dataset, blender, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORPO с PRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T23:18:26.817920Z",
     "iopub.status.busy": "2025-03-04T23:18:26.817663Z",
     "iopub.status.idle": "2025-03-04T23:18:27.180392Z",
     "shell.execute_reply": "2025-03-04T23:18:27.179395Z",
     "shell.execute_reply.started": "2025-03-04T23:18:26.817887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T23:18:27.181792Z",
     "iopub.status.busy": "2025-03-04T23:18:27.181503Z",
     "iopub.status.idle": "2025-03-04T23:18:27.187521Z",
     "shell.execute_reply": "2025-03-04T23:18:27.186684Z",
     "shell.execute_reply.started": "2025-03-04T23:18:27.181767Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ProbabilityRatioTrainer(ORPOTrainer):\n",
    "    def odds_ratio_loss(\n",
    "        self,\n",
    "        policy_chosen_logps: torch.FloatTensor,\n",
    "        policy_rejected_logps: torch.FloatTensor,\n",
    "    ) -> tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n",
    "        \"\"\"Compute ORPO's probability ratio (PR) loss for a batch of policy and reference model log probabilities.\n",
    "\n",
    "        Args:\n",
    "            policy_chosen_logps: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)\n",
    "            policy_rejected_logps: Log probabilities of the policy model for the rejected responses. Shape: (batch_size,)\n",
    "\n",
    "        Returns:\n",
    "            A tuple of three tensors: (losses, chosen_rewards, rejected_rewards).\n",
    "            The losses tensor contains the PR loss for each example in the batch.\n",
    "            The chosen_rewards and rejected_rewards tensors contain the rewards for the chosen and rejected responses, respectively.\n",
    "            The log probability ratio of the chosen responses over the rejected responses for logging purposes.\n",
    "            The `log(sigmoid(log_prob_ratio))` for logging purposes.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute the probability ratio\n",
    "        log_prob_ratio = policy_chosen_logps - policy_rejected_logps\n",
    "        ratio = F.logsigmoid(log_prob_ratio)\n",
    "        losses = -self.beta * ratio  # Negative because we want to maximize the ratio\n",
    "\n",
    "        # Compute rewards for logging\n",
    "        chosen_rewards = self.beta * (policy_chosen_logps.to(self.accelerator.device)).detach()\n",
    "        rejected_rewards = self.beta * (policy_rejected_logps.to(self.accelerator.device)).detach()\n",
    "\n",
    "        return losses, chosen_rewards, rejected_rewards, torch.mean(ratio), torch.mean(log_prob_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T23:18:27.188973Z",
     "iopub.status.busy": "2025-03-04T23:18:27.188597Z",
     "iopub.status.idle": "2025-03-04T23:18:27.724166Z",
     "shell.execute_reply": "2025-03-04T23:18:27.723338Z",
     "shell.execute_reply.started": "2025-03-04T23:18:27.188927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:18:27.725372Z",
     "iopub.status.busy": "2025-03-04T23:18:27.725136Z",
     "iopub.status.idle": "2025-03-05T00:37:51.588750Z",
     "shell.execute_reply": "2025-03-05T00:37:51.587537Z",
     "shell.execute_reply.started": "2025-03-04T23:18:27.725353Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff45c412a73543a6829b7fc884a4caba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76237bb480214f2c8c60bca4782ba6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='374' max='374' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [374/374 1:18:36, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.949900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.952100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.890800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.890200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.880300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.887100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.871100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.917800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.898600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.959900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.912200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.895200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.851400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.786400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.881400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.892900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.791100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.820600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.802400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.868600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.807600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.824400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.866100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.908800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.875900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.832800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.841400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.863400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.821100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.833700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.787000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.885100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=374, training_loss=1.870183730507917, metrics={'train_runtime': 4730.9388, 'train_samples_per_second': 2.536, 'train_steps_per_second': 0.079, 'total_flos': 0.0, 'train_loss': 1.870183730507917, 'epoch': 1.992})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ProbabilityRatioTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:37:51.590442Z",
     "iopub.status.busy": "2025-03-05T00:37:51.590157Z",
     "iopub.status.idle": "2025-03-05T00:38:52.588990Z",
     "shell.execute_reply": "2025-03-05T00:38:52.588222Z",
     "shell.execute_reply.started": "2025-03-05T00:37:51.590420Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Ranking candidates: 100%|██████████| 100/100 [00:39<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate: 4.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_win_rate(trainer.model, tokenizer, test_dataset, blender, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:38:52.590152Z",
     "iopub.status.busy": "2025-03-05T00:38:52.589902Z",
     "iopub.status.idle": "2025-03-05T00:38:53.314603Z",
     "shell.execute_reply": "2025-03-05T00:38:53.313685Z",
     "shell.execute_reply.started": "2025-03-05T00:38:52.590130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORPO + SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:38:53.315747Z",
     "iopub.status.busy": "2025-03-05T00:38:53.315458Z",
     "iopub.status.idle": "2025-03-05T00:38:53.774676Z",
     "shell.execute_reply": "2025-03-05T00:38:53.773905Z",
     "shell.execute_reply.started": "2025-03-05T00:38:53.315724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:38:53.776053Z",
     "iopub.status.busy": "2025-03-05T00:38:53.775710Z",
     "iopub.status.idle": "2025-03-05T00:38:53.786525Z",
     "shell.execute_reply": "2025-03-05T00:38:53.785817Z",
     "shell.execute_reply.started": "2025-03-05T00:38:53.776022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "strt_texts = []\n",
    "for dialog in test_dataset[\"chosen\"]:\n",
    "    strt_texts.append(tokenizer.apply_chat_template(dialog, tokenize=False))\n",
    "\n",
    "prompts = test_dataset[\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:38:53.788063Z",
     "iopub.status.busy": "2025-03-05T00:38:53.787839Z",
     "iopub.status.idle": "2025-03-05T00:38:54.282744Z",
     "shell.execute_reply": "2025-03-05T00:38:54.281678Z",
     "shell.execute_reply.started": "2025-03-05T00:38:53.788043Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdc18e1fb174b1cadb5ccbfca375ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_data(examples):\n",
    "    # formatted_prompts = []\n",
    "    # formatted_completions = []\n",
    "    # print(examples)\n",
    "    formatted_prompts = examples['prompt']\n",
    "    formatted_completions = tokenizer.apply_chat_template(examples['chosen'], tokenize=False)\n",
    "    return {\"prompt\": formatted_prompts, \"completion\": formatted_completions}\n",
    "\n",
    "formatted_dataset = train_dataset.map(format_data, batched=True)\n",
    "filtered_dataset = Dataset.from_dict({\n",
    "    \"prompt\": formatted_dataset[\"prompt\"],\n",
    "    \"completion\": formatted_dataset[\"completion\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:38:54.284013Z",
     "iopub.status.busy": "2025-03-05T00:38:54.283737Z",
     "iopub.status.idle": "2025-03-05T01:03:56.525918Z",
     "shell.execute_reply": "2025-03-05T01:03:56.524998Z",
     "shell.execute_reply.started": "2025-03-05T00:38:54.283992Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e397e3d9cfc4a02820c0ee5b393e321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac089c9d52184ca0b2714d9fee7d8047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52bedad1f334049abc768a874718b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e370d45f3a46e68989a90f13da9625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9371bc9b2b4f97970037b7600c4d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [187/187 24:33, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>13.112700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>12.350200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>12.357600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>12.230700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>11.936800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>12.390200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>12.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>11.795200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>11.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>12.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>11.936400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>12.462300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>11.917400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>12.130700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>11.664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>11.357300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>12.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>12.216000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args_sft = TrainingArguments(\n",
    "    output_dir=\"./results_sft\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate = 5e-5,\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args_sft,\n",
    "    train_dataset=filtered_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./results_sft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:03:56.527216Z",
     "iopub.status.busy": "2025-03-05T01:03:56.526876Z",
     "iopub.status.idle": "2025-03-05T01:43:57.426894Z",
     "shell.execute_reply": "2025-03-05T01:43:57.426097Z",
     "shell.execute_reply.started": "2025-03-05T01:03:56.527182Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/orpo_trainer.py:275: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b185ce4ab5492bbc46f943bb5b7220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [187/187 39:13, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.865800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.890800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.920300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.865400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.875800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.878400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.938800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.924300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.989300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.947800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.943900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.910900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.860900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.958400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.979200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=187, training_loss=1.9111019022324507, metrics={'train_runtime': 2367.5016, 'train_samples_per_second': 2.534, 'train_steps_per_second': 0.079, 'total_flos': 0.0, 'train_loss': 1.9111019022324507, 'epoch': 0.9973333333333333})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = ORPOConfig(output_dir=\"./orpo\",\n",
    "                           learning_rate = 8e-6,\n",
    "                           lr_scheduler_type=\"linear\",\n",
    "                           beta=0.1,\n",
    "                           per_device_train_batch_size=1,\n",
    "                           gradient_accumulation_steps=16,\n",
    "                           num_train_epochs=1,\n",
    "                           logging_steps=10,\n",
    "                           warmup_steps=10,\n",
    "                           report_to=\"none\")\n",
    "\n",
    "trainer = ORPOTrainer(model=model,\n",
    "                      args=training_args,\n",
    "                      processing_class=tokenizer,\n",
    "                      train_dataset=train_dataset)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:43:57.428091Z",
     "iopub.status.busy": "2025-03-05T01:43:57.427833Z",
     "iopub.status.idle": "2025-03-05T01:44:58.668185Z",
     "shell.execute_reply": "2025-03-05T01:44:58.667192Z",
     "shell.execute_reply.started": "2025-03-05T01:43:57.428071Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Ranking candidates: 100%|██████████| 100/100 [00:39<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate: 7.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_win_rate(model, tokenizer, test_dataset, blender, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:44:58.669383Z",
     "iopub.status.busy": "2025-03-05T01:44:58.669085Z",
     "iopub.status.idle": "2025-03-05T01:44:59.410338Z",
     "shell.execute_reply": "2025-03-05T01:44:59.409624Z",
     "shell.execute_reply.started": "2025-03-05T01:44:58.669349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR c SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:44:59.411797Z",
     "iopub.status.busy": "2025-03-05T01:44:59.411494Z",
     "iopub.status.idle": "2025-03-05T01:44:59.537433Z",
     "shell.execute_reply": "2025-03-05T01:44:59.536697Z",
     "shell.execute_reply.started": "2025-03-05T01:44:59.411774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"./results_sft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:44:59.538666Z",
     "iopub.status.busy": "2025-03-05T01:44:59.538379Z",
     "iopub.status.idle": "2025-03-05T01:44:59.543805Z",
     "shell.execute_reply": "2025-03-05T01:44:59.543074Z",
     "shell.execute_reply.started": "2025-03-05T01:44:59.538642Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
       "    num_rows: 6000\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:44:59.544825Z",
     "iopub.status.busy": "2025-03-05T01:44:59.544536Z",
     "iopub.status.idle": "2025-03-05T01:44:59.556989Z",
     "shell.execute_reply": "2025-03-05T01:44:59.556051Z",
     "shell.execute_reply.started": "2025-03-05T01:44:59.544804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ORPOTrainerlor(ORPOTrainer):\n",
    "   def get_batch_loss_metrics(\n",
    "        self,\n",
    "        model,\n",
    "        batch: dict[str, Union[list, torch.LongTensor]],\n",
    "        train_eval: Literal[\"train\", \"eval\"] = \"train\",\n",
    "    ):\n",
    "        \"\"\"Compute the OR loss and other metrics for the given batch of inputs for train or test.\"\"\"\n",
    "        metrics = {}\n",
    "\n",
    "        forward_output = self.concatenated_forward(model, batch)\n",
    "        (\n",
    "            policy_chosen_logps,\n",
    "            policy_rejected_logps,\n",
    "            policy_chosen_logits,\n",
    "            policy_rejected_logits,\n",
    "            policy_nll_loss,\n",
    "        ) = forward_output[:5]\n",
    "        if self.aux_loss_enabled:\n",
    "            aux_loss = forward_output[5]\n",
    "\n",
    "        # Compute log odds ratio loss\n",
    "        losses, chosen_rewards, rejected_rewards, log_odds_ratio, log_odds_chosen = self.odds_ratio_loss(\n",
    "            policy_chosen_logps, policy_rejected_logps\n",
    "        )\n",
    "        loss = -losses.mean()\n",
    "\n",
    "        reward_accuracies = (chosen_rewards > rejected_rewards).float()\n",
    "\n",
    "        prefix = \"eval_\" if train_eval == \"eval\" else \"\"\n",
    "        metrics[f\"{prefix}rewards/chosen\"] = self.accelerator.gather_for_metrics(chosen_rewards).mean()\n",
    "        metrics[f\"{prefix}rewards/rejected\"] = self.accelerator.gather_for_metrics(rejected_rewards).mean()\n",
    "        metrics[f\"{prefix}rewards/accuracies\"] = self.accelerator.gather_for_metrics(reward_accuracies).mean()\n",
    "        metrics[f\"{prefix}rewards/margins\"] = self.accelerator.gather_for_metrics(\n",
    "            chosen_rewards - rejected_rewards\n",
    "        ).mean()\n",
    "        metrics[f\"{prefix}logps/rejected\"] = self.accelerator.gather_for_metrics(policy_rejected_logps).detach().mean()\n",
    "        metrics[f\"{prefix}logps/chosen\"] = self.accelerator.gather_for_metrics(policy_chosen_logps).detach().mean()\n",
    "        metrics[f\"{prefix}logits/rejected\"] = (\n",
    "            self.accelerator.gather_for_metrics(policy_rejected_logits).detach().mean()\n",
    "        )\n",
    "        metrics[f\"{prefix}logits/chosen\"] = self.accelerator.gather_for_metrics(policy_chosen_logits).detach().mean()\n",
    "        metrics[f\"{prefix}nll_loss\"] = self.accelerator.gather_for_metrics(policy_nll_loss).detach().mean()\n",
    "        metrics[f\"{prefix}log_odds_ratio\"] = self.accelerator.gather_for_metrics(log_odds_ratio).mean()\n",
    "        metrics[f\"{prefix}log_odds_chosen\"] = self.accelerator.gather_for_metrics(log_odds_chosen).mean()\n",
    "        \n",
    "        # if is_torch_xla_available():\n",
    "        #     xm.mark_step()  # needed because .item() calls\n",
    "        \n",
    "        for k, v in metrics.items():\n",
    "            metrics[k] = v.item()\n",
    "        \n",
    "        if self.aux_loss_enabled:\n",
    "            loss += self.aux_loss_coef * aux_loss\n",
    "\n",
    "        return loss, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:44:59.558393Z",
     "iopub.status.busy": "2025-03-05T01:44:59.558058Z",
     "iopub.status.idle": "2025-03-05T02:24:51.572541Z",
     "shell.execute_reply": "2025-03-05T02:24:51.571529Z",
     "shell.execute_reply.started": "2025-03-05T01:44:59.558358Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/orpo_trainer.py:275: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ecf3a573e34e58bcee8387eae0254f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [187/187 38:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.069400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.075200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.071400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.068800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.068100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.070800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.073700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.072700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.071300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.071300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.071400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.074100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.071200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.068800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Ranking candidates: 100%|██████████| 100/100 [00:39<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate: 11.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = ORPOConfig(output_dir=\"./orpo\",\n",
    "                           learning_rate = 8e-6,\n",
    "                           lr_scheduler_type=\"linear\",\n",
    "                           beta=0.1,\n",
    "                           per_device_train_batch_size=1,\n",
    "                           gradient_accumulation_steps=16,\n",
    "                           num_train_epochs=1,\n",
    "                           logging_steps=10,\n",
    "                           warmup_steps=10,\n",
    "                           report_to=\"none\")\n",
    "\n",
    "\n",
    "\n",
    "trainer = ORPOTrainerlor(model=model,\n",
    "                      args=training_args,\n",
    "                      processing_class=tokenizer,\n",
    "                      train_dataset=train_dataset)\n",
    "\n",
    "# Дообучаем модель\n",
    "trainer.train()\n",
    "\n",
    "calculate_win_rate(model, tokenizer, test_dataset, blender, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
